{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P06_03_programme.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HhSf1ZI6cyb",
        "outputId": "d08606b3-a88d-4a10-fd30-dab50b0b7a2f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYplp5MB6gGP"
      },
      "source": [
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#from skimage.io import imread\n",
        "#from skimage.transform import resize\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "#from imgaug import augmenters as iaa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.utils import *\n",
        "from keras.callbacks import *\n",
        "from keras.preprocessing.image import *\n",
        "\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bcIENJH7a8Y"
      },
      "source": [
        "\n",
        "breed_list = os.listdir(\"/content/drive/MyDrive/input/images/Images/\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmIbD5sR6kSH"
      },
      "source": [
        "# Mapping of labels and numbers\n",
        "label_maps = {}\n",
        "label_maps_rev = {}\n",
        "for i, v in enumerate(breed_list[:10]):\n",
        "    label_maps.update({v: i})\n",
        "    label_maps_rev.update({i : v})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk0P_fGm6sIZ"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0T84vWa6yWL"
      },
      "source": [
        "def paths_and_labels():\n",
        "    paths = list()\n",
        "    labels = list()\n",
        "    targets = list()\n",
        "    for breed in breed_list[:10]:\n",
        "        base_name = \"/content/drive/MyDrive/data/{}/\".format(breed)\n",
        "        for img_name in os.listdir(base_name):\n",
        "            paths.append(base_name + img_name)\n",
        "            labels.append(breed)\n",
        "            targets.append(label_maps[breed])\n",
        "    return paths, labels, targets\n",
        "\n",
        "paths, labels, targets = paths_and_labels()\n",
        "\n",
        "assert len(paths) == len(labels)\n",
        "assert len(paths) == len(targets)\n",
        "num_classes = len(breed_list)\n",
        "targets = keras.utils.to_categorical(targets, num_classes=num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXWUex5L6ywV",
        "outputId": "879d2ddf-da76-46ed-e944-399f14542e9d"
      },
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/data\"\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen_mc = ImageDataGenerator(rescale=1./255,\n",
        "                                   zca_whitening=True,\n",
        "                                   horizontal_flip=True, \n",
        "                                   validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_1 = train_datagen_mc.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training') \n",
        "\n",
        "validation_generator_1 = train_datagen_mc.flow_from_directory(\n",
        "    train_data_dir, \n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1474 images belonging to 10 classes.\n",
            "Found 363 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXyfdm3t7AB5",
        "outputId": "8e0dd288-ce17-4a39-b33d-78c3785901e6"
      },
      "source": [
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze four convolution blocks\n",
        "for layer in vgg_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Make sure you have frozen the correct layers\n",
        "for i, layer in enumerate(vgg_model.layers):\n",
        "    print(i, layer.name, layer.trainable)\n",
        "\n",
        "x = vgg_model.output\n",
        "x = Flatten()(x) # Flatten dimensions to for use in FC layers\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x) # Dropout layer to reduce overfitting \n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(10, activation='softmax')(x) # Softmax for multiclass\n",
        "transfer_model = Model(inputs=vgg_model.input, outputs=x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "0 input_1 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_pool False\n",
            "11 block4_conv1 False\n",
            "12 block4_conv2 False\n",
            "13 block4_conv3 False\n",
            "14 block4_pool False\n",
            "15 block5_conv1 True\n",
            "16 block5_conv2 True\n",
            "17 block5_conv3 True\n",
            "18 block5_pool True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LNk0jev6_47"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                              factor=0.6,\n",
        "                              patience=8, \n",
        "                              verbose=1, \n",
        "                              mode='max', \n",
        "                              min_lr=5e-5)\n",
        "checkpoint = ModelCheckpoint('vgg16_finetune.h15', \n",
        "                             monitor= 'val_accuracy', \n",
        "                             mode= 'max',\n",
        "                             save_best_only = True, verbose= 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYKpx0gM6_st"
      },
      "source": [
        "from tensorflow.keras import layers, models, Model, optimizers"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGYShCrU6zAv",
        "outputId": "240e4f3e-bd31-4feb-8bc6-2bfd3c40d6af"
      },
      "source": [
        "#Compile model\n",
        "learning_rate= 5e-5\n",
        "nb_epochs = 10\n",
        "transfer_model.compile(loss=\"categorical_crossentropy\", \n",
        "                       optimizer=optimizers.Adam(lr=learning_rate), \n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "#Fit model\n",
        "history = transfer_model.fit_generator(train_generator_1, \n",
        "                                       steps_per_epoch = train_generator_1.samples // batch_size,\n",
        "                                       validation_data = validation_generator_1, \n",
        "                                       validation_steps = validation_generator_1.samples // batch_size,\n",
        "                                       epochs = nb_epochs, \n",
        "                                       shuffle=True, \n",
        "                                       callbacks=[lr_reduce],\n",
        "                                       verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "46/46 [==============================] - 1075s 24s/step - loss: 2.2104 - accuracy: 0.1921 - val_loss: 1.8920 - val_accuracy: 0.2983\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1049s 23s/step - loss: 1.6998 - accuracy: 0.3675 - val_loss: 1.4723 - val_accuracy: 0.4659\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1047s 23s/step - loss: 1.3067 - accuracy: 0.5451 - val_loss: 1.2399 - val_accuracy: 0.5653\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1048s 23s/step - loss: 1.0550 - accuracy: 0.6214 - val_loss: 1.1648 - val_accuracy: 0.5710\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1046s 23s/step - loss: 0.7821 - accuracy: 0.7309 - val_loss: 1.2858 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1043s 23s/step - loss: 0.6959 - accuracy: 0.7691 - val_loss: 0.9748 - val_accuracy: 0.6562\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1062s 23s/step - loss: 0.4912 - accuracy: 0.8329 - val_loss: 0.9639 - val_accuracy: 0.6449\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1043s 23s/step - loss: 0.4065 - accuracy: 0.8662 - val_loss: 0.9660 - val_accuracy: 0.6761\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1046s 23s/step - loss: 0.3877 - accuracy: 0.8779 - val_loss: 0.9793 - val_accuracy: 0.6875\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1045s 23s/step - loss: 0.2495 - accuracy: 0.9307 - val_loss: 0.9973 - val_accuracy: 0.6818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP5n_wYq7eWc",
        "outputId": "2ead584f-c07f-40d4-9679-4c6e5ecd1df0"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-2.3.6-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting Flask-Cors>=3.0.8\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.1)\n",
            "Collecting Flask-Login\n",
            "  Downloading Flask_Login-0.5.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5)\n",
            "Collecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting flask-cachebuster\n",
            "  Downloading Flask-CacheBuster-1.0.0.tar.gz (3.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5)\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n",
            "Collecting markdown2\n",
            "  Downloading markdown2-2.4.1-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.10.4-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors>=3.0.8->gradio) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
            "Building wheels for collected packages: ffmpy, flask-cachebuster\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=a88b81f2ecb40772b72f4d5ce73ac1c15f175d9f5a7650046d944faa5e06d370\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-py3-none-any.whl size=3371 sha256=8a4dec1239da0d2590a8695e2f4ed7ad7affc9ea9fe88fb6fc418f5c01c20193\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/c0/c4/44687421dab41455be93112bd1b0dee1f3c5a9aa27bee63708\n",
            "Successfully built ffmpy flask-cachebuster\n",
            "Installing collected packages: pynacl, monotonic, cryptography, bcrypt, backoff, pycryptodome, paramiko, markdown2, Flask-Login, Flask-Cors, flask-cachebuster, ffmpy, analytics-python, gradio\n",
            "Successfully installed Flask-Cors-3.0.10 Flask-Login-0.5.0 analytics-python-1.4.0 backoff-1.10.0 bcrypt-3.2.0 cryptography-35.0.0 ffmpy-0.3.0 flask-cachebuster-1.0.0 gradio-2.3.6 markdown2-2.4.1 monotonic-1.6 paramiko-2.7.2 pycryptodome-3.10.4 pynacl-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy1Q4LQi7eO2"
      },
      "source": [
        "import gradio\n",
        "# Load the model\n",
        "model_dog_breeds = transfer_model\n",
        "\n",
        "#Load the labels\n",
        "labels_dog_breeds = breed_list[:10]\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QkYOUSe7d_Z"
      },
      "source": [
        "#------------------#\n",
        "\n",
        "# Function for preprocessing an image and predicting the dog breed\n",
        "def classify_image(image_):\n",
        "    img = image_.reshape((-1,224, 224, 3))\n",
        "    prediction = model_dog_breeds.predict(img).flatten()\n",
        "\n",
        "    return {labels_dog_breeds[i]: float(prediction[i]) for i in range(10)}\n",
        "\n",
        "# Define the inputs, outputs\n",
        "image = gradio.inputs.Image(shape=(224,224))\n",
        "label = gradio.outputs.Label(num_top_classes=3)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "1swSojId8BhW",
        "outputId": "ab5e23ef-a29c-4d22-d09f-f164fd2be102"
      },
      "source": [
        "#------------------#\n",
        "\n",
        "# Launch the application\n",
        "gradio.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=image,\n",
        "    outputs=label,\n",
        "    title=\"Image classification - limited to 10 dog breeds\",\n",
        ").launch(debug=False)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
            "Running on External URL: https://56769.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://56769.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ff4214e2f10>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://56769.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daSktvwQ8GIZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}